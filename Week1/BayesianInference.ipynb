{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16d6d55d",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "\n",
    "Implement Bayesian inference\n",
    "1) Randomly generate n (2D) random samples from a MVN with mean [-1, 1]; covariance [2, 1.3; 1.3; 4] \n",
    "2) Use Gibbs sampling to infer unknown parameters : mean & covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5321f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9072da59",
   "metadata": {},
   "source": [
    "# 1 Generate Data from MVN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fedb10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 123\n",
    "rng = np.random.default_rng(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57a88d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "μ = np.array([-1, 1])\n",
    "Σ = np.array([[2, 1.3], [1.3, 4]])\n",
    "X = np.random.multivariate_normal(μ, Σ, size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f837aa",
   "metadata": {},
   "source": [
    "# 2 Bayesian Inference Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71642c8",
   "metadata": {},
   "source": [
    "### Posterior distribution (Normal Inverse Wishart) of $\\mu$ and $\\Sigma$\n",
    "\n",
    "(From Murphy)\n",
    "\n",
    "$$\\begin{align}\n",
    "\n",
    "    p(\\mu,\\Sigma | D) &= \\mathcal{N}(\\mu|\\mathbf{m}_N, \\frac{1}{\\kappa_N}\\Sigma) \\times \\mathcal{IW}(\\Sigma | \\mathbf{S}_N, \\nu_N)\\\\ &= \\mathcal{NIW}(\\mu,\\Sigma | \\mathbf{m}_N, \\kappa_N, \\nu_N, \\mathbf{S}_N)\\\\\\\\\n",
    "\n",
    "    m_N &= \\frac{\\kappa_0\\mathbf{m}_0 + N\\bar{\\mathbf{x}}}{\\kappa_0 + N}, \\qquad \\text{weighted average between prior and observed}\\\\\n",
    "    \\kappa_N &= \\kappa_0 + N\\\\\n",
    "    \\nu_N &= \\nu_0 + N \\\\\n",
    "    \\mathbf{S}_N &= \\mathbf{S}_0 + \\mathbf{S}_{\\bar{\\mathbf{x}}} + \\frac{\\kappa_0N}{\\kappa_0 + N}(\\bar{\\mathbf{x}} - \\mathbf{m}_0)(\\bar{\\mathbf{x}} - \\mathbf{m}_0)^T, \\qquad \\text{$\\bar{x}$ : observed sample mean, use $\\mu$ for conditional posterior}\\\\ \n",
    "    &= \\mathbf{S}_0 + \\mathbf{S} + \\kappa_0\\mathbf{m}_0\\mathbf{m}_0^T - \\kappa_N\\mathbf{m}_N\\mathbf{m}_N^T \\\\\n",
    "\n",
    "    \\mathbf{S} &= \\sum_{i=1}^{N} (\\bar{x} - \\mu_0)(\\bar{x} - \\mu_0)^T, \\quad \\text{use $\\mu$ instead of $\\bar{x}$ for conditional posterior}\n",
    "    \n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030c73f4",
   "metadata": {},
   "source": [
    "### Gibbs Routine:\n",
    "1) Intialize $\\mu$ and $\\Sigma$ as well as\n",
    "\n",
    "$$\\begin{align}\n",
    "    \\bar{x} &= \\frac{1}{N}\\sum_{i=0}^N \\mathbf{x}_i, & \\qquad \\text{Observed sample mean}\\\\\n",
    "    k_0 &= 0.01, & \\qquad \\text{prior confidence hyperparameter}\\\\\n",
    "    k_n &= k_0 + n & \\\\ \n",
    "    \\mu_0 &= \\texttt{zero}_d, &\\qquad \\text{prior belief about mean, hyperparameter}\\\\\n",
    "    \\nu_0 &= d + 2, &\\qquad \\text{IW DOF hyperparameter}\\\\\n",
    "    \\nu_n &= \\nu_0 + n, &\\\\\n",
    "    S_0 &= M_{identity}, &\\qquad \\text{Prior believe about scatter matrix}\n",
    "\\end{align}$$\n",
    "\n",
    "2) for $t=1,...,N$  \n",
    "$$\\begin{align}\n",
    "    \\text{Sample } \\mu^{(t)} &\\sim \\mathcal{N}(\\mu|\\mathbf{m}_n^{(t)}, \\frac{1}{\\kappa_n}\\Sigma^{(t-1)})\\\\\n",
    "        \\mu_n &= \\frac{k_0\\mu_0 + n\\bar{x}}{k_0 + n}\\\\\n",
    "        \\Sigma_n &= \\frac{\\Sigma^{(t-1)}}{k_n}\\\\\n",
    "        \\mu^{(t)} &\\sim \\mathcal{N}(\\mu_n, \\Sigma_n)\\\\\\\\\n",
    "    \n",
    "    \\text{Sample } \\Sigma^{(t)} &\\sim \\mathcal{IW}(\\Sigma | \\mathbf{S}_n^{(t)}, \\nu_N^{(t)})\\\\\n",
    "        S &= \\sum_{i=1}^{N} (\\mu^{(t)} - \\mu_0)(\\mu^{(t)} - \\mu_0)^T\\\\\n",
    "        S_n &= S_0 + S + \\frac{\\kappa_0n}{\\kappa_0 + n}(\\mu^{(t)} - \\mu_0)(\\mu^{(t)} - \\mu_0)^T\\\\\n",
    "        \\Sigma^{(t)} &\\sim \\mathcal{IW}(S_N, \\nu_n)\n",
    "\n",
    "\\end{align}$$\n",
    "\n",
    "\n",
    "$\\qquad$ Keep Samples $\\mu^{(t)}$ and $\\Sigma^{(t)}$  \n",
    "\n",
    "3) Discard burn in samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10526cce",
   "metadata": {},
   "source": [
    "### 2.1 MVN Approach for Sampling from Wishart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4e7645",
   "metadata": {},
   "source": [
    "From Murphy  (p. 126) : \n",
    "\n",
    "$$\\begin{align}\n",
    "\\text{Let $x_i \\sim \\mathcal{N}(0,\\Sigma)$. Then the scatter matrix $\\mathbf{S} = \\sum_{i=1}^{N}\\mathbf{x_i}\\mathbf{x_i}^T$ has a Wishart distribution $\\mathbf{S} \\sim \\mathcal{Wi}(\\Sigma, N)$. Hence $\\mathop{\\mathbb{E}}[S] = N\\Sigma$.}\n",
    "\\end{align}$$\n",
    "\n",
    "\n",
    "Hence to sample from Wishart $\\mathcal{W}(\\nu_n,S_n)$, we generate samples $\\mathbf{Z} = [\\mathbf{z}_1,...,\\mathbf{z}_{\\nu_n}]$ from MVN with $\\theta = (0, S_n)$, and compute scatter $\\mathbf{S} = Z^TZ$ where $\\mathbf{S} \\sim \\mathcal{W}(\\nu_n,S_n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb0ae58",
   "metadata": {},
   "source": [
    "For inverse Wishart\n",
    "\n",
    "#### Step 1 : Draw Gaussians \n",
    "\n",
    "\n",
    "$\\qquad Z \\sim \\mathcal{N}(0, S_n^{-1})$\n",
    "\n",
    "\n",
    "$\\quad$ where $Z = [z_1,...,z_{v_n}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23815a97",
   "metadata": {},
   "source": [
    "#### Step 2 : Form Wishart \n",
    "$\\qquad W = Z^TZ \\sim \\mathcal{W}(\\nu, S_n^{-1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec71acf3",
   "metadata": {},
   "source": [
    "#### Step 3 : Invert \n",
    "$\\qquad \\Sigma = W^{-1} \\sim \\mathcal{W}^{-1}(\\nu, S_n)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f180cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs(X, num_iters, num_burn, eps=1e-14):\n",
    "    n,d = X.shape\n",
    "\n",
    "    x_bar = X.mean(axis=0)\n",
    "\n",
    "    μ_samples = np.zeros((num_iters + num_burn, d))\n",
    "    Σ_samples = np.zeros((num_iters + num_burn, d, d))\n",
    "\n",
    "    k_0 = 0.01         # Prior confidence in μ_0\n",
    "    k_n = k_0 + n      \n",
    "    μ_0 = np.zeros(d)  # Prior mean vector \n",
    "    ν_0 = d + 1        # DOF for inverse wishart\n",
    "    ν_n = ν_0 + n\n",
    "    S_0 = np.eye(d)    # positive definite prior scatter matrix\n",
    "\n",
    "    # Initialize\n",
    "    Σ_samples[0] = np.cov(X.T)\n",
    "    μ_samples[0] = x_bar.copy()\n",
    "\n",
    "    for i in range(1, num_iters + num_burn):\n",
    "        # Sample μ\n",
    "        μ_n = (k_0 * μ_0 + n * x_bar) / k_n\n",
    "        Σ_n = Σ_samples[i-1]/k_n\n",
    "        μ = np.random.multivariate_normal(mean=μ_n, cov=Σ_n)\n",
    "\n",
    "        # Sample Σ\n",
    "        S = (X - μ).T @ (X - μ)\n",
    "        diff = (μ - μ_0).reshape(-1,1)\n",
    "        S_n = S_0 + S +(k_0 * n / k_n) * (diff @ diff.T)\n",
    "\n",
    "        z = np.random.multivariate_normal(np.zeros(d), np.linalg.inv(S_n), size=ν_n)\n",
    "        W = z.T @ z\n",
    "        Sigma = np.linalg.inv(W)\n",
    "\n",
    "        if i == 1 : \n",
    "            print(z.shape)\n",
    "\n",
    "        # Store\n",
    "        μ_samples[i] = μ\n",
    "        Σ_samples[i] = Sigma\n",
    "\n",
    "    return μ_samples[num_burn:], Σ_samples[num_burn:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51039f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(503, 2)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "mus, sigmas = gibbs(X,10000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9e2df3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.78242882  1.25685339] [[2.00521997 1.49836065]\n",
      " [1.49836065 4.00728158]]\n"
     ]
    }
   ],
   "source": [
    "print(mus[-1], sigmas[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cd57ca",
   "metadata": {},
   "source": [
    "### 2.2 Bartlett (Cholesky) Decomposition for Sampling from Inverse-Wishart\n",
    "1. https://en.wikipedia.org/wiki/Wishart_distribution\n",
    "2. https://djalil.chafai.net/blog/2015/10/20/bartlett-decomposition-and-other-factorizations/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75df3c29",
   "metadata": {},
   "source": [
    "\n",
    "#### Step 1:  Construct lower-trangular matrix T \n",
    "$\\qquad$ Diagonal Elements  \n",
    "$$\\begin{align}\n",
    "    T_{ii} \\sim \\sqrt{\\mathcal{X}^2_{\\nu  - i + 1}}  \\qquad \\text{for $i = 1,...,d$}\n",
    "\\end{align}$$\n",
    "\n",
    "$\\qquad$ Below Diagonal Elements  \n",
    "$$\\begin{align}\n",
    "    T_{ij} \\sim \\mathcal{N}(0,1), \\qquad \\text{for $j < i$}\n",
    "\\end{align}$$\n",
    "\n",
    "$\\qquad$ Above Diagonal Elements \n",
    "$$\\begin{align}\n",
    "    T_{ij} = 0, \\qquad \\text{for $j>i$}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0a64cf",
   "metadata": {},
   "source": [
    "#### Step 2 : Compute $A = TT^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9869ef",
   "metadata": {},
   "source": [
    "#### Step 3 : Apply desired scale matrix $S_n$\n",
    "1) Compute $L = Cholesky(S_n)$, such that $S_n = LL^T$\n",
    "2) Construct final Wishart sample \n",
    "$$\\begin{align}\n",
    "    W = LAL^T \\sim \\mathcal{W}(S_n, \\nu)\n",
    "\\end{align}$$\n",
    "\n",
    "Inverse Wishart \n",
    "$$\\begin{align} \n",
    "    \\mathcal{W}^{-1}(\\nu, S_n) \\equiv \\mathcal{W}(\\nu, S_n^{-1})\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab49e8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs(X, num_iters, num_burn, eps=1e-14):\n",
    "    n,d = X.shape\n",
    "\n",
    "    x_bar = X.mean(axis=0)\n",
    "\n",
    "    μ_samples = np.zeros((num_iters + num_burn, d))\n",
    "    Σ_samples = np.zeros((num_iters + num_burn, d, d))\n",
    "\n",
    "    k_0 = 0.01\n",
    "    k_n = k_0 + n\n",
    "    μ_0 = np.zeros(d)\n",
    "    ν_0 = d + 1\n",
    "    S_0 = np.eye(d)\n",
    "    ν_n = ν_0 + n\n",
    "\n",
    "\n",
    "    # Initialize\n",
    "    Σ_samples[0] = np.cov(X.T)\n",
    "    μ_samples[0] = x_bar.copy()\n",
    "\n",
    "    for t in range(1, num_iters + num_burn):\n",
    "        # Sample μ\n",
    "        μ_n = (k_0 * μ_0 + n * x_bar) / k_n\n",
    "        Σ_n = Σ_samples[t-1]/k_n\n",
    "        μ = np.random.multivariate_normal(mean=μ_n, cov=Σ_n)\n",
    "\n",
    "        # Sample Σ\n",
    "        S = (X - μ).T @ (X - μ)\n",
    "        diff = (μ - x_bar)\n",
    "        S_n = S_0 + S +(k_0 * n / k_n) * (diff @ diff.T)\n",
    "\n",
    "        # Sample from Inverse-Wishart using Bartlett decomposition\n",
    "        T = np.zeros((d, d))\n",
    "\n",
    "        for i in range(d):\n",
    "            T[i,i] = np.sqrt(np.random.chisquare(df=ν_n - i))\n",
    "            if i + 1 < d : \n",
    "                T[i + 1:, 1] = np.random.normal(size = d - i - 1)\n",
    "\n",
    "        A = T @ T.T\n",
    "        L = np.linalg.cholesky(np.linalg.inv(S_n))\n",
    "        W = L @ A @ L.T\n",
    "        Sigma = np.linalg.inv(W)\n",
    "\n",
    "        # Store\n",
    "        μ_samples[t] = μ\n",
    "        Σ_samples[t] = Sigma\n",
    "\n",
    "    return μ_samples[num_burn:], Σ_samples[num_burn:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f2e61b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mus, sigmas = gibbs(X,10000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5eeae6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.99086839  1.01494283] [[2.10558622 1.36146191]\n",
      " [1.36146191 3.90556251]]\n"
     ]
    }
   ],
   "source": [
    "print(mus[-1], sigmas[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b9704a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
