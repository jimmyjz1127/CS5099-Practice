{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "9ddad2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "%config Completer.use_jedi = False\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from scipy.special import logsumexp\n",
    "from scipy.special import softmax\n",
    "from scipy.special import betaln\n",
    "from scipy.special import beta\n",
    "\n",
    "import numpy.linalg as linalg\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "import scipy.sparse as sparse\n",
    "import random\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b697b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 123\n",
    "rng = np.random.default_rng(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c51157",
   "metadata": {},
   "source": [
    "# Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "3d6aca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.draw import disk, rectangle, polygon\n",
    "\n",
    "def generate_shape(shape, std=0.1, size=10):\n",
    "    img = np.zeros((size, size), dtype=np.float32)\n",
    "    center1 = np.round(size // 2 + np.random.uniform(-size//15,size//15)).astype(np.int16)\n",
    "    center2 = np.round(size // 2 + np.random.uniform(-size//15,size//15)).astype(np.int16)\n",
    "    \n",
    "    if shape == 'circle':\n",
    "        rr, cc = disk((center1, center1), radius=size//3, shape=img.shape)\n",
    "        img[rr, cc] = 1\n",
    "    elif shape == 'square':\n",
    "        s = size // 3\n",
    "        rr, cc = rectangle((center1-s, center2-s), extent=(2*s, 2*s), shape=img.shape)\n",
    "        img[rr, cc] = 1\n",
    "    elif shape == 'triangle':\n",
    "        s = size // 3\n",
    "        points = [(center1, center2 - s), (center1 - s, center2 + s), (center1 + s, center2 + s)]\n",
    "        rr, cc = polygon([p[0] for p in points], [p[1] for p in points], shape=img.shape)\n",
    "        img[rr, cc] = 1\n",
    "    elif shape == 'plus':\n",
    "        t = 1\n",
    "        img[center1 - t:center1 + t + 1, :] = 1\n",
    "        img[:, center2 - t:center2 + t + 1] = 1\n",
    "    elif shape == \"bar\" :\n",
    "        t = 1\n",
    "        img[:, center1 - t:center2 + t + 1] = 1\n",
    "    else:\n",
    "        raise ValueError(\"Unknown shape\")\n",
    "    \n",
    "    return img+  np.random.normal(0, std, size=img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "da8bb013",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = ['square','triangle','bar','plus']\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx,shape in enumerate(shapes):\n",
    "    for _ in range(1000):\n",
    "        X.append(generate_shape(shape))\n",
    "        y.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "5689b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(len(X), -1)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "75e17707",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "5cefebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bin = X_train > 0.5\n",
    "X_test_bin = X_test > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "8de7963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', Normalizer())\n",
    "])\n",
    "\n",
    "X_train_prepared = pipeline.fit_transform(X_train)\n",
    "X_test_prepared = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "3e1065d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"shapes\"\n",
    "\n",
    "np.save(f\"./../Datasets/Gaussian/Processed/{name}/X_train_{name}.npy\",X_train_prepared)\n",
    "np.save(f\"./../Datasets/Gaussian/Processed/{name}/X_test_{name}.npy\",X_test_prepared)\n",
    "np.save(f\"./../Datasets/Gaussian/Processed/{name}/y_train_{name}.npy\",y_train)\n",
    "np.save(f\"./../Datasets/Gaussian/Processed/{name}/y_test_{name}.npy\",y_test)\n",
    "\n",
    "np.save(f\"./../Datasets/Bernoulli/Processed/{name}/X_train_{name}.npy\", X_train_bin)\n",
    "np.save(f\"./../Datasets/Bernoulli/Processed/{name}/X_test_{name}.npy\", X_test_bin)\n",
    "np.save(f\"./../Datasets/Bernoulli/Processed/{name}/y_train_{name}.npy\", y_train)\n",
    "np.save(f\"./../Datasets/Bernoulli/Processed/{name}/y_test_{name}.npy\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7a117b",
   "metadata": {},
   "source": [
    "# Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "4feb1dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wishart, multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "576d218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wishart_covariances(K, D, df=None, rng=None):\n",
    "    rng = rng or np.random.default_rng()\n",
    "    df = df or D + 2  # degrees of freedom must be >= D\n",
    "\n",
    "    covs = []\n",
    "    for _ in range(K):\n",
    "        scale_matrix = np.eye(D)\n",
    "        cov = wishart(df=df, scale=scale_matrix, seed=rng).rvs()\n",
    "        covs.append(cov)\n",
    "\n",
    "    return np.array(covs)\n",
    "\n",
    "def generate_means(covariances):\n",
    "    K,D,D = covariances.shape\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    m_0 = np.zeros((D))\n",
    "    k = 0.01\n",
    "\n",
    "    means = []\n",
    "\n",
    "    for cov in covariances:\n",
    "        mean = rng.multivariate_normal(m_0, cov/k)\n",
    "        means.append(mean)\n",
    "\n",
    "    return means\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "59baadd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariances = generate_wishart_covariances(10, 10)\n",
    "means = generate_means(covariances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "b00f2bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "for idx, (cov, mean) in enumerate(zip(covariances, means)):\n",
    "    X_k = rng.multivariate_normal(mean, cov, size=500)\n",
    "    y_k = np.full(500, idx)  # more efficient than list comprehension\n",
    "    X.append(X_k)\n",
    "    y.append(y_k)\n",
    "\n",
    "X = np.vstack(X)  # shape: (K * 1000, D)\n",
    "y = np.concatenate(y)  # shape: (K * 1000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b31abb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "40144ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"synthetic\"\n",
    "\n",
    "np.save(f\"./../Datasets/Gaussian/Processed/{name}/X_train_{name}.npy\",X_train)\n",
    "np.save(f\"./../Datasets/Gaussian/Processed/{name}/X_test_{name}.npy\",X_test)\n",
    "np.save(f\"./../Datasets/Gaussian/Processed/{name}/y_train_{name}.npy\",y_train)\n",
    "np.save(f\"./../Datasets/Gaussian/Processed/{name}/y_test_{name}.npy\",y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcf2528",
   "metadata": {},
   "source": [
    "# Synthetic Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541431e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bernoulli_parameters(K, D, rng=None):\n",
    "    rng = rng or np.random.default_rng()\n",
    "    return rng.uniform(low=0.1, high=0.9, size=(K, D))\n",
    "def generate_bernoulli_mixture_data(θ, n_per_cluster=1000, rng=None):\n",
    "    rng = rng or np.random.default_rng()\n",
    "    K, D = θ.shape\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for k in range(K):\n",
    "        samples = rng.binomial(n=1, p=θ[k], size=(n_per_cluster, D))\n",
    "        labels = np.full(n_per_cluster, k)\n",
    "\n",
    "        X.append(samples)\n",
    "        y.append(labels)\n",
    "\n",
    "    X = np.vstack(X)  # shape (K * n_per_cluster, D)\n",
    "    y = np.concatenate(y)  # shape (K * n_per_cluster,)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d56c6db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
